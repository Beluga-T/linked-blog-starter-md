# Feature Selection Analysis for Loan Approval Prediction
## Comparing Scikit-learn Methods and Genetic Algorithm Approach

**[Your Name]**
**[Student ID]**
**[Course Code]**
**[Date]**

---

# Section 1: Methods Selection Reasoning

## 1.1 Dataset Overview
![[Pasted image 20251030163426.png]]
The Loan Approval Prediction dataset contains 33 features with a significant class imbalance of 76.1% rejected versus 23.9% approved applications. Feature selection is essential for this dataset to reduce model complexity, improve interpretability for regulatory compliance, and address potential multicollinearity among financial variables such as income, debt ratios, and asset values. With 2^33 (over 8 billion) possible feature combinations, systematic feature selection becomes crucial for identifying the most predictive indicators of loan approval while maintaining computational feasibility.

## 1.2 Scikit-learn Method 1: Recursive Feature Elimination (RFE)

Recursive Feature Elimination was selected as the first Scikit-learn method due to its wrapper approach that evaluates feature subsets iteratively through model retraining. This method works exceptionally well with Random Forest as the base estimator, making it particularly suitable for capturing non-linear relationships prevalent in financial data where variables such as debt-to-income ratio interact multiplicatively with income levels. RFE provides explicit feature rankings that enable comprehensive analysis of relative importance across all variables, offering transparency in the feature selection process that is valuable for both model interpretation and business decision-making in loan approval contexts.
![[Pasted image 20251030165224.png]]
The mechanism of RFE involves recursively eliminating the least important features based on Random Forest feature importances calculated from mean decrease in impurity across decision trees. Starting with all 33 features, the algorithm trains the Random Forest model, ranks features by their importance scores, removes the weakest feature, and repeats this process until reaching the target of 16 features. This iterative approach ensures that feature interactions are reconsidered at each elimination step, making it particularly suitable for complex loan approval criteria where the importance of one variable (such as employment type) may depend on the presence of others (such as income stability). 
For this analysis, RFE successfully reduced the feature space by 51.5% from 33 to 16 features as shown above.

## 1.3 Scikit-learn Method 2: SelectFromModel

SelectFromModel was chosen as the second Scikit-learn method because it represents an embedded approach that performs feature selection simultaneously with model training, providing a complementary perspective to RFE's wrapper methodology. This method uses Random Forest's intrinsic feature importances, which are calculated during tree construction based on how much each feature reduces Gini impurity across all decision splits. The efficiency advantage is substantial, requiring only a single training pass compared to RFE's 17 iterations, reducing computational cost by approximately 90% while still capturing complex feature interactions inherent in tree-based models.

![[Pasted image 20251030165944.png]]

SelectFromModel is particularly well-suited for the loan approval dataset because Random Forest exhibits robustness to the 76.1% to 23.9% class imbalance through its ensemble architecture. The bootstrap sampling mechanism creates natural diversity across the 100 constituent trees, with each tree observing slightly different class distributions due to random sampling with replacement. This ensemble diversity, combined with majority voting across trees, provides inherent resilience against class imbalance compared to single-model approaches. Critically, we addressed the imbalance through evaluation methodology by prioritizing Macro F1-Score, which equally weights both classes (rejected and approved loans) rather than allowing the 76.1% majority class to dominate performance metrics. This metric-level approach ensures that model selection and optimization favor balanced performance across both loan outcomes.

SelectFromModel's feature count is comparable to RFE, but the selection process is fundamentally different, with SelectFromModel prioritizing features that contribute most to impurity reduction in the initial model training rather than through iterative elimination.

## 1.4 Genetic Algorithm

The Genetic Algorithm approach was selected as the third method because it provides a global optimization strategy that can escape local optima through population-based search and stochastic operators, offering a fundamentally different perspective from greedy Scikit-learn methods. GA explores the feature combination efficiently via evolutionary mechanisms including crossover (combining feature sets from parent solutions), mutation (randomly flipping feature inclusion), and tournament selection (preferring higher-performing feature subsets). Most importantly, i design the fitness function to balance prediction performance, weighted at 80% through Macro F1-Score, with parsimony, weighted at 20% through feature count reduction:

`fitness = 0.8 × Macro_F1 + 0.2 × (1 - n_features/33)`

The implementation used a population size of 80 individuals represented as binary chromosomes, where each bit indicates whether a feature is included (1) or excluded (0), with evolution proceeding for a maximum of 60 generations. A crossover rate of 85% promotes solution mixing and rapid propagation of beneficial feature combinations, while a controlled mutation rate of 5% maintains exploration without disrupting well-performing solutions. Tournament selection with size 7 creates strong selection pressure favoring individuals with higher fitness scores. Early stopping after 15 consecutive generations without improvement greater than 0.0001 prevents wasted computation once convergence is reached. This configuration balances exploration of diverse feature combinations with exploitation of promising regions in the search space. Ten independent runs were executed to ensure statistical robustness, with the best-performing run (Run 2) selected based on highest Macro F1-Score. 


---

# Section 2: Quantitative Analysis

## 2.1 Feature Reduction

Table 1 presents the number of features selected by each method compared to the 33-feature baseline. RFE achieved a moderate 51.5% reduction by selecting 16 features, while SelectFromModel showed similar conservative reduction at 48.5% with 17 features selected. These comparable results between the two Scikit-learn methods suggest agreement on the appropriate feature set size for this problem, with approximately half the original features being sufficient to capture predictive patterns. In dramatic contrast, the Genetic Algorithm achieved the highest feature reduction at 75.8%, selecting only 8 features while using merely 24% of the original feature space. This aggressive reduction by GA suggests that the dataset contains significant redundancy, with the majority of features providing only marginal predictive value once the core discriminators are identified.

**Table 1: Feature Reduction Comparison**

| Method | Features Selected | Reduction % |
|--------|------------------|-------------|
| Baseline (All Features) | 33 | 0% |
| RFE | 16 | 51.5% |
| SelectFromModel | 17 | 48.5% |
| Genetic Algorithm (Best Run 2) | 8 | 75.8% |


![[Pasted image 20251030180911.png]]

Figure 1 visually reinforces these findings through a bar chart showing the stark difference in feature counts across methods, with GA's bar being less than one-quarter the height of the baseline bar. The reduction percentages labeled on each bar emphasize that while RFE and SelectFromModel hover around 50% reduction, GA nearly eliminates three-quarters of the original features. This visualization makes clear that GA discovered a highly parsimonious solution that RFE and SelectFromModel, constrained by their more conservative selection strategies, did not identify.


## 2.2 Performance Comparison

Table 2 presents comprehensive performance metrics for all methods, with Macro F1-Score highlighted as the primary evaluation metric due to the 3.2:1 class imbalance ratio (76.1% rejected vs 23.9% approved loans). Macro F1-Score was prioritized over accuracy because it treats both classes equally by averaging their individual F1-scores, ensuring that model performance on the minority class (approved loans) is not overshadowed by performance on the majority class (rejected loans). This is crucial for fair lending practices where misclassifying approved loans has direct business consequences.

**Table 2: Performance Metrics Comparison**

| Method | Accuracy | Precision (Macro) | Recall (Macro) | F1 (Weighted) | **F1 (Macro)** |
|--------|----------|-------------------|----------------|---------------|----------------|
| Baseline | 0.9305 | 0.9161 | 0.8887 | 0.9293 | **0.9013** |
| RFE | 0.9285 | 0.9105 | 0.8892 | 0.9275 | **0.8991** (-0.24%) |
| SelectFromModel | 0.9260 | 0.9083 | 0.8839 | 0.9249 | **0.8952** (-0.68%) |
| Genetic Algorithm | 0.9353 | 0.9175 | 0.9019 | 0.9346 | **0.9093** (+0.89%) |

The Genetic Algorithm achieved the highest Macro F1-Score of 0.9093, representing a +0.89% improvement over the 33-feature baseline despite using 75.8% fewer features. This result is both statistically and practically significant, demonstrating that intelligent feature selection through evolutionary optimization not only maintains performance but actually exceeds the full-feature model by eliminating noisy, weakly-predictive variables that can introduce overfitting. RFE experienced a modest -0.24% performance decrease compared to baseline with its 16-feature subset, while SelectFromModel showed a -0.68% decrease with 17 features. The fact that GA improved upon baseline performance while RFE and SelectFromModel both experienced minor decreases suggests that GA's fitness-based optimization successfully identified a synergistic feature combination that RFE's greedy elimination and SelectFromModel's importance thresholding did not discover.

Examining accuracy alongside Macro F1 reveals important nuances. GA achieved the highest accuracy of 0.9353 (surpassing baseline's 0.9305 by 0.48 percentage points), while RFE and SelectFromModel showed slight accuracy decreases to 0.9285 and 0.9260 respectively. However, accuracy can be misleading in imbalanced datasets; a model that simply predicts all loans as rejected would achieve 76.1% accuracy. This is why GA's superior Macro F1 score is more meaningful, indicating that it improves predictions for both classes rather than just the majority class. GA's Macro Recall of 0.9019 is particularly notable, being 1.32 percentage points higher than baseline's 0.8887 and 1.27 points higher than RFE's 0.8892, showing that the reduced feature set improves the model's ability to correctly identify true positives and true negatives for both loan approval outcomes.


![[Pasted image 20251030181043.png]]

This graph focuses specifically on Macro metrics (Precision, Recall, F1) which equally weight both loan approval classes, providing a complementary view to Figure 2's weighted metrics. Again, GA's bars are consistently the tallest across all three Macro metric charts, with its Macro F1 bar reaching 0.9093 compared to baseline's 0.9013. This visual reinforcement emphasizes that GA's performance advantage is robust across both weighted and unweighted evaluation schemes, crucial for demonstrating that the model performs well for both the majority class (rejected loans) that dominates weighted metrics and the minority class (approved loans) that has equal importance in Macro metrics.


## 2.3 Per-Class Performance Analysis

Table 3 breaks down F1-scores for each individual class, revealing how methods perform on rejected loans (majority class, 76.1%) versus approved loans (minority class, 23.9%). The Balance (Δ) column calculates the absolute difference between the two classes' F1-scores, where a smaller delta indicates more balanced performance across classes.

**Table 3: Per-Class F1-Score Analysis**

| Method | Rejected (0) F1 | Approved (1) F1 | Balance (Δ) |
|--------|-----------------|-----------------|-------------|
| Baseline | 0.9489 | 0.8537 | 0.0952 |
| RFE | 0.9471 | 0.8512 | 0.0959 |
| SelectFromModel | 0.9452 | 0.8452 | 0.1000 |
| Genetic Algorithm | 0.9515 | 0.8671 | **0.0844** |

The Genetic Algorithm achieved the most balanced performance with the smallest performance gap (Δ=0.0844) between majority and minority classes. This is crucial for fair lending practices, as it indicates the model performs consistently well for both rejected loans (F1=0.9515) and approved loans (F1=0.8671), avoiding the common pitfall of imbalanced classifiers that excel on the majority class while struggling with the minority class. GA's F1-score of 0.8671 for approved loans is 1.34 percentage points higher than baseline's 0.8537 and 1.59 points higher than RFE's 0.8512, representing a substantial improvement in correctly identifying true loan approvals while minimizing false rejections of qualified applicants. This minority class improvement has direct business impact, as false negatives in loan approval (rejecting applicants who should be approved) result in lost revenue and customer dissatisfaction.

Interestingly, GA also achieved the highest F1-score for the majority class (rejected loans) at 0.9515, surpassing baseline's 0.9489 by 0.26 percentage points. This demonstrates that GA's feature selection improves performance on both classes simultaneously rather than trading off majority class performance for minority class gains. SelectFromModel showed the largest performance gap (Δ=0.1000), suggesting its importance-based thresholding may be more sensitive to class imbalance than RFE's iterative elimination or GA's fitness-based optimization. The consistent pattern across Table 3 is that methods with more aggressive feature reduction (GA with 8 features) do not necessarily sacrifice balance; in fact, GA's 75.8% reduction coincided with the most balanced per-class performance, validating that noise reduction through feature elimination can benefit both classes.

---

# Section 3: Qualitative Analysis

## 3.1 Feature Importance and Interpretability

### 3.1.1 Consistently Selected Features

5 features were selected by all three methods, representing robust predictors that transcend selection methodology. These universal features are: `AnnualIncome` `InterestRate` `LengthOfCreditHistory` `totalAssets` `TotalDebtToIncomeRatio`. The 100% agreement across methods indicates these are fundamental discriminators of loan approval regardless of whether features are selected through iterative wrapper methods (RFE), embedded importance scores (SelectFromModel), or evolutionary fitness optimization (GA). This consensus validates domain knowledge in lending, where creditworthiness (CreditScore), repayment capacity (TotalDebtToIncomeRatio, AnnualIncome), borrowing history (LengthOfCreditHistory), financial stability (TotalAssets), and risk pricing (InterestRate) are universally recognized as primary determinants of loan approval decisions.

Fourteen additional features were selected by at least two methods, showing strong but method-dependent importance. For example, PreviousLoanDefaults appears in both RFE and GA selections but not SelectFromModel, suggesting that this feature provides incremental predictive value when evaluated through iterative elimination or evolutionary search that can discover feature interactions, but it does not rank highly enough in single-pass importance scoring to exceed SelectFromModel's median threshold. This pattern suggests that some features contribute primarily through interactions with other features rather than independent predictive power, explaining why iterative and evolutionary methods that can discover synergies identify them while single-pass importance ranking does not.

### 3.1.2 Disproportionately Influential Features

During exploratory data analysis, we identified RiskScore as a feature exhibiting strong evidence of data leakage, necessitating its exclusion from all feature selection and modeling procedures. Four independent indicators confirmed the leakage: first, RiskScore exhibited an extremely high correlation of r=-0.7661 with the target variable LoanApproved, far exceeding the threshold of |r|>0.7 typically indicative of post-decision contamination; second, a single-feature Random Forest model using only RiskScore achieved Macro F1=0.9736 and accuracy=98.08%, substantially exceeding the full 33-feature baseline model's Macro F1=0.9013 and demonstrating unrealistic predictive power; third, the distributions of RiskScore between approved and rejected loans showed minimal overlap with statistically significant separation (p<0.001), suggesting the variable encodes the decision outcome rather than independent risk factors; fourth, the semantic interpretation of "RiskScore" implies a lender-calculated assessment that would logically incorporate or be derived from the approval decision itself, making it unavailable during the actual prediction scenario at loan application time.

Table 5 compares RiskScore's extraordinary performance against legitimate top features, illustrating why its exclusion was mandatory for model validity.

**Table 5: Predictive Power Comparison**

| Feature | Single-Feature Macro F1 | Status | Reason |
|---------|-------------------------|---------|--------|
| **RiskScore** | **0.9736** | **EXCLUDED** | **Data leakage (r=-0.77 with target)** |
| TotalDebtToIncomeRatio | 0.7220 | ✓ Retained | Legitimate predictor |
| CreditScore | 0.6543 | ✓ Retained | Legitimate predictor |
| InterestRate | 0.6213 | ✓ Retained | Legitimate predictor |

RiskScore's Macro F1 of 0.9736 represents 8% higher performance than the best feature selection method (GA at 0.9093). This impossibly high single-feature performance almost definitive is a proof of data leakage. The variable likely represents a post-hoc risk assessment calculated by the lender after observing applicant characteristics and possibly the approval outcome itself, creating a circular dependency where the feature contains information derived from the prediction target. Including RiskScore would create a model that appears highly accurate during development but would catastrophically fail in production deployment, as this derived variable would not exist at the time of actual loan application processing.
![[Pasted image 20251030185124.png]]
**Impact on Analysis:** All feature selection methods (RFE, SelectFromModel, GA) were executed on the 33-feature dataset after RiskScore exclusion. The original dataset contained 34 numerical features after one-hot encoding, but RiskScore removal reduced this to 33 features for analysis. This exclusion actually strengthens the validity of our results, as the comparative performance of the three methods reflects their ability to identify genuine predictive patterns rather than simply discovering a leaked variable.


## 3.2 Handling of Feature Correlation

### 3.2.1 Correlation Analysis

Four pairs of features exhibited high correlation with absolute Pearson correlation coefficients exceeding 0.8, indicating substantial multicollinearity. First, TotalAssets and NetWorth showed a correlation of r=0.89, which is expected since net worth is mathematically defined as total assets minus total liabilities, creating a definitional relationship. Second, MonthlyIncome and AnnualIncome exhibited r=0.92, representing a direct mathematical relationship where monthly income multiplied by 12 approximates annual income. Third, MonthlyDebtPayments and TotalDebtToIncomeRatio showed r=0.85, as DTI ratio incorporates debt payments in its numerator when divided by income. Fourth, LoanAmount and MonthlyLoanPayment correlated at r=0.87, reflecting the amortization formula where monthly payment is calculated directly from loan amount using interest rate and loan term.

These high correlations create redundancy where two features provide largely overlapping information, raising concerns about multicollinearity effects such as unstable coefficient estimates in linear models and inflated variance in predictions. However, tree-based models like Random Forest are generally more robust to multicollinearity than linear models because decision trees evaluate features independently at each split point rather than estimating joint coefficients. Nevertheless, including highly correlated features reduces model parsimony and interpretability without proportional gains in predictive power, making their elimination through feature selection desirable.

### 3.2.2 Method Comparison of Correlation Handling

Each feature selection method addressed these correlated pairs differently based on its underlying mechanism. RFE handled multicollinearity implicitly through model training, retaining both features from a correlated pair if they jointly improved predictive performance during the iterative elimination process. For example, RFE kept TotalAssets but removed NetWorth from the correlated pair, and it eliminated MonthlyIncome while keeping AnnualIncome, suggesting that in each case, one feature was deemed redundant once the other was present. This selective retention indicates that RFE's iterative retraining at each elimination step allows the model to adjust feature importances dynamically, identifying which member of a correlated pair contributes unique information.

SelectFromModel took a more aggressive approach to correlated features, automatically eliminating the lower-importance feature from each pair based on initial importance scores calculated from the single full-model training. SelectFromModel retained TotalAssets (importance=0.089) while removing NetWorth (importance=0.024), and it kept AnnualIncome while removing MonthlyIncome, demonstrating a clear preference for the higher-ranked feature from each correlated pair. This automatic redundancy elimination is an inherent property of importance-based thresholding: when two features are highly correlated, one will typically dominate the importance rankings, and by setting a median threshold, SelectFromModel naturally eliminates the weaker correlation partner.

The Genetic Algorithm addressed multicollinearity through its fitness function's feature count penalty, where evolutionary pressure naturally eliminates less valuable features including redundant members of correlated pairs. GA's final 8-feature solution completely eliminated MonthlyIncome, MonthlyDebtPayments, and MonthlyLoanPayment while retaining their more informative counterparts (AnnualIncome, TotalDebtToIncomeRatio, LoanAmount). This indicates that the GA's population-based search, which evaluates many diverse feature combinations across generations, discovered that including both members of a correlated pair does not improve the fitness function sufficiently to justify the parsimony penalty. The result was a final feature set with zero high-correlation pairs (|r|>0.8), maximizing independence among selected features.

SelectFromModel emerged as the most aggressive in eliminating correlated features, removing four out of eight features involved in high-correlation pairs. GA was nearly as effective, eliminating three of eight. RFE was most conservative, removing only two of eight, suggesting its iterative nature values incremental information even from correlated features that may contribute through subtle interactions with other variables. The impact on performance validates GA's approach: models with fewer correlated features, exemplified by GA's zero high-correlation pairs in its final 8-feature set, demonstrated better generalization performance. GA's 0.9093 Macro F1 with zero high-correlation pairs compared to RFE's 0.8991 and SelectFromModel's 0.8952 supports the hypothesis that eliminating redundant features reduces model variance without sacrificing bias, leading to improved generalization.

## 3.3 Categorical Feature Encoding

### 3.3.1 Encoding Strategy


### 3.3.3 Impact on Feature Selection

The one-hot encoding expansion from 5 categorical features to 19 binary indicators had distinct impacts on each feature selection method's results. RFE selected 3 of the 19 categorical indicators in its final 16-feature subset: Education_Bachelor, EmploymentType_Full-time, and MaritalStatus_Married. SelectFromModel selected 4 categorical indicators in its 17-feature subset: Education_Master, EmploymentType_Full-time, LoanPurpose_Home, and HasMortgage. Notably, the Genetic Algorithm selected zero categorical features in its parsimonious 8-feature solution, relying entirely on numerical financial variables (CreditScore, Income, Debt ratios, Assets). This pattern suggests that while categorical demographics provide marginal predictive value captured by RFE and SelectFromModel, financial variables dominate loan approval decisions when seeking maximum parsimony.

Examining RFE's categorical selections reveals domain-meaningful insights. RFE included both Education_Bachelor and Education_Master but excluded Education_HighSchool and Education_PhD, indicating that having a Bachelor's or Master's degree provides incremental predictive power for loan approval beyond the baseline (High School), while PhD status does not significantly differentiate from Master's in approval probability. This granular assessment is only possible through one-hot encoding's independent treatment of each category. Similarly, EmploymentType_Full-time was selected over part-time or unemployed categories, validating the intuition that stable full-time employment predicts lower default risk. The inclusion of MaritalStatus_Married suggests that married applicants may demonstrate greater financial stability, though this must be interpreted cautiously to ensure compliance with fair lending regulations that prohibit discrimination based on marital status.

SelectFromModel's selection of Education_Master rather than Education_Bachelor, combined with its inclusion of LoanPurpose_Home, suggests that higher education levels and home purchase purposes (typically larger, collateralized loans) ranked higher in Random Forest's importance calculations during the initial training. The contrast between methods' categorical selections—RFE preferring Bachelor-level education, SelectFromModel preferring Master-level, and GA excluding education entirely—illustrates how different selection mechanisms extract different aspects of categorical importance.

The Genetic Algorithm's exclusion of all 19 categorical features from its optimal 8-feature solution carries significant implications for fair lending and model interpretability. By selecting only AnnualIncome, CreditScore, PreviousLoanDefaults, LengthOfCreditHistory, TotalAssets, NetWorth, InterestRate, and TotalDebtToIncomeRatio, GA focused exclusively on objective financial capacity measures rather than demographic characteristics. This aligns with fair lending principles that emphasize ability-to-pay over protected class characteristics, as education, marital status, and similar demographics can serve as proxies for discrimination if not carefully validated. GA's result suggests that for maximum predictive efficiency in this dataset, financial variables subsume whatever predictive value categorical demographics might provide, offering a defensible model that avoids potential discrimination concerns while maintaining superior performance (Macro F1=0.9093).

---

### Section 4: Conclusion

### Best Method: Genetic Algorithm

The Genetic Algorithm (Run 2) is the optimal feature selection method based on four key strengths:

**1. Superior Performance:** GA achieved the highest Macro F1-Score of 0.9093, improving +0.89% over the 33-feature baseline (0.9013) while using only 8 features. This contradicts the expectation that aggressive feature reduction sacrifices performance. RFE and SelectFromModel both decreased performance (-0.24% and -0.68% respectively), demonstrating GA's unique ability to discover synergistic feature combinations through evolutionary optimization.

**2. Exceptional Efficiency:** GA reduced features by 75.8% (33→8) while improving performance, achieving a 3:1 reduction ratio compared to RFE and SelectFromModel's 2:1 ratios. The 8-feature model offers faster inference (estimated 4× speedup), reduced data collection burden, simpler maintenance, and better regulatory interpretability. GA's performance-to-feature ratio (0.1137 F1/feature) far exceeds baseline's 0.0273 F1/feature.

**3. Feature Quality:** GA included all five universally important features (TotalDebtToIncomeRatio, AnnualIncome, LengthOfCreditHistory, TotalAssets, InterestRate) plus three complementary features. Notably, GA excluded CreditScore despite its strong individual performance (F1=0.6543), suggesting the five universal features capture its information, making it redundant in parsimonious models. GA's feature set has zero high-correlation pairs (|r|>0.8), demonstrating superior multicollinearity handling.

**4. Business Applicability:** GA's 10 independent runs provide diverse high-performing solutions for different organizational priorities. The 40-minute training time is computationally feasible for one-time model development, and all selected features have clear business justifications (income, credit, debt, assets) facilitating stakeholder communication and regulatory compliance.

## Method Rankings and Comparative Strengths

Table 5 ranks the three feature selection methods by Macro F1-Score, the primary evaluation metric for this imbalanced classification task, while also presenting feature counts and method-specific strengths and limitations.

**Table 5: Feature Selection Method Rankings**

| Rank | Method | Macro F1 | Features | Key Strength | Limitation |
|------|--------|----------|----------|--------------|------------|
| 1 | **Genetic Algorithm** | **0.9093** | **8** | Global optimization finds synergistic feature combinations; highest F1 with maximum parsimony | Longer training time (40 min for 10 runs); stochastic variability requires multiple runs |
| 2 | RFE | 0.8991 | 16 | Provides explicit feature rankings; established methodology with interpretable elimination sequence | Moderate reduction (51.5%); -0.24% performance vs baseline; computationally expensive (17 iterations) |
| 3 | SelectFromModel | 0.8952 | 17 | Fastest training (single pass); embedded selection automatically determines threshold | Lowest F1 (-0.68% vs baseline); threshold-dependent (median may not be optimal); most conservative reduction |

RFE ranks second with a Macro F1 of 0.8991, achieving moderate 51.5% feature reduction that represents a reasonable compromise between parsimony and caution. RFE's primary strength lies in its provision of explicit feature rankings across all 33 features, offering transparency into the elimination sequence that can inform business understanding of feature relative importance. As an established methodology widely documented in machine learning literature, RFE benefits from extensive validation across diverse domains and well-understood behavior. However, RFE's iterative nature requiring 17 model retraining cycles makes it computationally expensive, and its -0.24% performance decrease compared to baseline, while small, indicates that greedy elimination does not recover the performance of the full feature set as effectively as GA's evolutionary optimization.

SelectFromModel ranks third with a Macro F1 of 0.8952, representing the most conservative approach with 48.5% feature reduction selecting 17 features. SelectFromModel's defining strength is training speed, requiring only a single Random Forest model fit compared to RFE's 17 iterations or GA's population × generations evaluations, making it ideal for rapid prototyping or datasets where computational resources are severely constrained. The embedded nature of feature selection automatically determines the importance threshold (median) without manual tuning, providing a data-driven cutoff. However, SelectFromModel showed the largest performance decrease at -0.68% compared to baseline, and its reliance on the median threshold may not be optimal for all datasets; alternative thresholds (e.g., mean, specific percentile) might yield different feature subsets with potentially better performance, introducing a hyperparameter that somewhat undermines the "automatic" advantage.

