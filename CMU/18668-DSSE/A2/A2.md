# Section 1: Methods Selection Reasoning

## 1.1 Dataset Overview
![[Pasted image 20251030163426.png]]
The Loan Approval Prediction dataset contains 33 features with a significant class imbalance of 76.1% rejected versus 23.9% approved applications. Feature selection is essential for this dataset to reduce model complexity, improve interpretability for regulatory compliance, and address potential multicollinearity among financial variables such as income, debt ratios, and asset values. 
## 1.2 Scikit-learn Method 1: Recursive Feature Elimination (RFE)

Recursive Feature Elimination was selected  due to its wrapper approach that evaluates feature subsets iteratively through model retraining. RFE provides explicit feature rankings that enable comprehensive analysis of relative importance across all variables, offering transparency in the feature selection process that is valuable for both model interpretation and business decision-making in loan approval contexts.
![[Pasted image 20251030165224.png|500]]
RFE removes the least important features iteratively based on Random Forest impurity-based importance scores. It starts with all 33 features, retrains and ranks them, drops the weakest feature each round, and continues until 16 features remain. This step-wise process re-evaluates interactions at each stage, which is useful when feature importance depends on the presence of others—as is common in loan approval data. In this study, RFE reduced the feature set by 51.5%, from 33 to 16 features.

## 1.3 Scikit-learn Method 2: SelectFromModel

SelectFromModel serves as an efficient embedded alternative to RFE, using Random Forest impurity-based importances to select features in a single training pass while still capturing non-linear interactions.

![[Pasted image 20251030165944.png|500]]

SelectFromModel is particularly suitable for this loan approval dataset because Random Forest naturally mitigates the 76.1% vs. 23.9% class imbalance through bootstrap sampling and ensemble voting, giving each tree slightly different class proportions and improving robustness compared to single-model approaches. We further addressed imbalance by prioritizing Macro F1-Score, ensuring equal emphasis on approved and rejected loans rather than letting the majority class dominate performance.

SelectFromModel's feature count is comparable to RFE, but the selection process is fundamentally different, with SelectFromModel prioritizing features that contribute most to impurity reduction in the initial model training rather than through iterative elimination.

## 1.4 Genetic Algorithm

GA explores the feature combination efficiently via evolutionary mechanisms including crossover (combining feature sets from parent solutions), mutation (randomly flipping feature inclusion), and tournament selection (preferring higher-performing feature subsets). Most importantly, i design the fitness function to balance prediction performance, weighted at 80% through Macro F1-Score, with parsimony, weighted at 20% through feature count reduction:

`fitness = 0.8 × Macro_F1 + 0.2 × (1 - n_features/33)`

The GA used a population of 80 binary chromosomes (1 = feature included), evolving for up to 60 generations. We applied an 85% crossover rate for efficient mixing and a 5% mutation rate to maintain exploration, with tournament selection (size = 7) to prefer higher-fitness solutions. Early stopping triggered after 15 stagnant generations (Δ<0.0001), and we ran the algorithm 10 times for robustness, selecting the best run (Run 2) based on the highest Macro F1 score.


---

# Section 2: Quantitative Analysis

## 2.1 Feature Reduction


![[Pasted image 20251030180911.png|450]]

**Table: Feature Reduction Comparison**

| Method                         | Features Selected | Reduction % |
| ------------------------------ | ----------------- | ----------- |
| Baseline (All Features)        | 33                | 0%          |
| RFE                            | 16                | 51.5%       |
| SelectFromModel                | 17                | 48.5%       |
| Genetic Algorithm (Best Run 2) | 8                 | 75.8%       |
Table and graph above presents the number of features selected by each method compared to the 33-feature baseline. RFE achieved a moderate 51.5% reduction by selecting 16 features, while SelectFromModel showed similar conservative reduction at 48.5% with 17 features selected.

The GA achieved the highest feature reduction at `75.8%`, selecting only 8 features out of 33. This aggressive reduction by GA suggests that the dataset contains significant redundancy, with the majority of features providing only marginal predictive value once the core discriminators are identified.
## 2.2 Performance Comparison

Table 2 presents comprehensive performance metrics for all methods. `Macro F1-Score` was prioritized over accuracy because it treats both classes equally by averaging their individual F1-scores, ensuring that model performance on the minority class (approved loans) is not overshadowed by performance on the majority class (rejected loans). This is crucial for fair lending practices where misclassifying approved loans has direct business consequences.

**Table 2: Performance Metrics Comparison**

| Method | Accuracy | Precision (Macro) | Recall (Macro) | F1 (Weighted) | **F1 (Macro)** |
|--------|----------|-------------------|----------------|---------------|----------------|
| Baseline | 0.9305 | 0.9161 | 0.8887 | 0.9293 | **0.9013** |
| RFE | 0.9285 | 0.9105 | 0.8892 | 0.9275 | **0.8991** (-0.24%) |
| SelectFromModel | 0.9260 | 0.9083 | 0.8839 | 0.9249 | **0.8952** (-0.68%) |
| Genetic Algorithm | 0.9353 | 0.9175 | 0.9019 | 0.9346 | **0.9093** (+0.89%) |

The Genetic Algorithm achieved the highest Macro F1 (0.9093), improving +0.89% over the 33-feature baseline while using 75.8% fewer features. This shows that evolutionary optimization not only preserved performance but surpassed the full-feature model by removing noisy and weak predictors. In contrast, RFE and SelectFromModel showed small declines (-0.24% and -0.68%), indicating that GA identified a more synergistic feature subset than RFE’s greedy elimination or SelectFromModel’s importance-thresholding approach.


![[Pasted image 20251030181043.png|550]]

This graph focuses specifically on Macro metrics (Precision, Recall, F1) which equally weight both loan approval classes, providing a complementary view to Figure 2's weighted metrics. Again, GA's bars are consistently the tallest across all three Macro metric charts, with its Macro F1 bar reaching 0.9093 compared to baseline's 0.9013. This shows that the model performs well for both the majority class (rejected loans) that dominates weighted metrics and the minority class (approved loans) that has equal importance in Macro metrics.
## 2.3 Per-Class Performance Analysis

The table compares class-specific F1-scores and the Balance (Δ) gap, where a smaller Δ means more balanced performance between approved and rejected loans.

**Table: Per-Class F1-Score Analysis**

| Method | Rejected (0) F1 | Approved (1) F1 | Balance (Δ) |
|--------|-----------------|-----------------|-------------|
| Baseline | 0.9489 | 0.8537 | 0.0952 |
| RFE | 0.9471 | 0.8512 | 0.0959 |
| SelectFromModel | 0.9452 | 0.8452 | 0.1000 |
| Genetic Algorithm | 0.9515 | 0.8671 | **0.0844** |

The Genetic Algorithm achieved the smallest class gap (Δ=0.0844), indicating balanced performance across rejected (F1=0.9515) and approved loans (F1=0.8671). Its approved-loan F1 exceeded both the baseline (+1.34 points) and RFE (+1.59 points), reducing costly false rejections while still slightly improving majority-class performance (0.9515 vs. 0.9489). In contrast, SelectFromModel showed the largest imbalance (Δ=0.1000). Overall, GA’s 8-feature subset improved both fairness and accuracy, demonstrating that removing redundant or noisy features can strengthen performance across classes.

---

# Section 3: Qualitative Analysis

## 3.1 Feature Importance and Interpretability

### 3.1.1 Consistently Selected Features

5 features were selected by all three methods, representing robust predictors that transcend selection methodology. These universal features are: `AnnualIncome` `InterestRate` `LengthOfCreditHistory` `totalAssets` `TotalDebtToIncomeRatio`. The 100% agreement across methods indicates these are fundamental discriminators of loan approval regardless of whether features are selected through iterative wrapper methods (RFE), embedded importance scores (SelectFromModel), or evolutionary fitness optimization (GA).

14 additional features were selected by at least two methods, showing strong but method-dependent importance. Some features contribute primarily through interactions with other features rather than independent predictive power, explaining why iterative and evolutionary methods that can discover synergies identify them while single-pass importance ranking does not.

### 3.1.2 Disproportionately Influential Features

![[Pasted image 20251031063813.png|550]]
During exploratory analysis, we identified `RiskScore` as a clear data-leakage feature and removed it before feature selection and modeling. It showed an extremely strong correlation with the target (r = −0.7661), far exceeding the typical |r| > 0.7 leakage threshold, indicating it likely encodes post-decision information.

**Table: Predictive Power Comparison**

| Feature                | Single-Feature Macro F1 | Status       | Reason                                 |
| ---------------------- | ----------------------- | ------------ | -------------------------------------- |
| **RiskScore**          | **0.9736**              | **EXCLUDED** | **Data leakage (r=-0.77 with target)** |
| TotalDebtToIncomeRatio | 0.7220                  | Retained     | Legitimate predictor                   |
| CreditScore            | 0.6543                  | Retained     | Legitimate predictor                   |
| InterestRate           | 0.6213                  | Retained     | Legitimate predictor                   |
RiskScore achieved a Macro F1 of 0.9736, about 8% higher than the best feature-selected model (GA at 0.9093). This unrealistically strong single-feature performance clearly indicates data leakage. The feature likely reflects a post-decision lender risk assessment that already incorporates approval information, creating a circular dependency. Using it would inflate development accuracy but fail in real deployment, since this score would not be available at application time

![[Pasted image 20251030185124.png|500]]
All feature selection methods (RFE, SelectFromModel, GA) were executed on the 33-feature dataset after RiskScore exclusion. The original dataset contained 34 numerical features after one-hot encoding, but RiskScore removal reduced this to 33 features for analysis. This exclusion actually strengthens the validity of our results, as the comparative performance of the three methods reflects their ability to identify genuine predictive patterns rather than simply discovering a leaked variable.

## 3.2 Handling of Feature Correlation

### 3.2.1 Correlation Analysis
![[Pasted image 20251031061904.png|560]]

#### Table: High Correlation Feature Pairs (|r| > 0.8)

| Feature 1        | Feature 2     | Correlation (r) | RFE           | SelectFromModel  | GA                |
| ---------------- | ------------- | --------------- | ------------- | ---------------- | ----------------- |
| Age              | Experience    | 0.983           | Both selected | Neither selected | Neither selected  |
| AnnualIncome     | MonthlyIncome | 0.990           | Both selected | Both selected    | AnnualIncome only |
| TotalAssets      | NetWorth      | 0.979           | Both selected | Both selected    | TotalAssets only  |
| BaseInterestRate | InterestRate  | 0.835           | Both selected | Both selected    | InterestRate only |

The table above shjow 4 pairs of features exhibited high correlation with absolute Pearson correlation coefficients exceeding 0.8, indicating substantial multicollinearity. 

These high correlations create redundancy where two features provide largely overlapping information, raising concerns about multicollinearity effects such as unstable coefficient estimates in linear models and inflated variance in predictions.

However, tree-based models like Random Forest are generally more robust to multicollinearity than linear models because decision trees evaluate features independently at each split point rather than estimating joint coefficients. 

### 3.2.2 Method Comparison of Correlation Handling

Each feature selection method addressed these correlated pairs differently based on its underlying mechanism. SelectFromModel emerged as the most aggressive in eliminating corrlated features, removing four out of eight features involved in high-correlation pairs. 
GA was nearly as effective, eliminating three of eight. RFE was most conservative, removing only two of eight, suggesting its iterative nature values incremental information even from correlated features that may contribute through subtle interactions with other variables. 

GA's 0.9093 Macro F1 with zero high-correlation pairs compared to RFE's 0.8991 and SelectFromModel's 0.8952 supports the hypothesis that eliminating redundant features reduces model variance without sacrificing bias, leading to improved generalization.

## 3.3 Categorical Feature Encoding

### 3.3.1 Encoding Strategy

Five categorical features (e.g., `EmploymentStatus`, `EducationLevel`, `MaritalStatus`, etc.) were converted to numeric form for the Random Forest model. We applied label encoding, assigning each category a unique integer. This preserved the original 33-feature dimensionality (after removing RiskScore), since each categorical variable remained a single column rather than being expanded into multiple one-hot indicators.
### 3.3.2 Label Encoding in Tree-Based Models

Label encoding works effectively with Random Forest because decision trees split on thresholds rather than interpreting numeric values as continuous magnitudes. Thus, a split like “EmploymentStatus ≤ 1” partitions categories without implying that 0 < 2 has semantic meaning. For nominal features (e.g., LoanPurpose), the artificial ordering could introduce bias, but Random Forest mitigates this through random feature selection, diverse tree structures, and ensemble aggregation, which collectively capture category relationships and reduce dependence on any single encoded ordering.

### 3.3.3 Impact on Feature Selection

Label encoding influenced feature selection outcomes: none of the three methods ultimately retained categorical variables. RFE (16 features), SelectFromModel (17 features), and GA (8 features) all selected only numerical financial features, suggesting that credit and capacity metrics dominate loan approval prediction, while demographic categories provide limited incremental value once financial indicators are present.

Firsst, label-encoded categorical variables produce lower importance scores in Random Forest because they offer fewer levels and coarser segmentation than continuous features like income or debt ratios. Second, financial variables already encode much of the signal that categorical attributes represent—for example, education and employment status correlate with earning power and repayment stability—making categorical variables largely redundant in this context.

### Section 4: Conclusion

RFE ranks second with a Macro F1 of 0.8991 and a 51.5% feature reduction, offering a balanced trade-off between compactness and caution. Its key strength is transparent feature ranking, which supports interpretability and model governance. However, its small  performance drop vs. baseline shows that greedy elimination does not match GA’s global optimization ability.

SelectFromModel places third with a Macro F1 of 0.8952 and a 48.5% reduction (17 features). Its main advantage is efficiency—only one model fit—making it well-suited for fast experimentation or limited compute environments. But it had the largest performance decrease (−0.68%), and its fixed median-importance threshold may not be ideal for all datasets, potentially requiring tuning despite being positioned as “automatic.”
#### Best Method: Genetic Algorithm

The Genetic Algorithm (Run 2) is the best feature selection method. It achieved the highest Macro F1-Score (0.9093), a +0.89% improvement over the 33-feature baseline, while using only 8 features (-75.8%). Unlike RFE and SelectFromModel, which both reduced performance, GA found a synergistic subset that improved accuracy and fairness. With just 8 features, the model is faster, easier to maintain, requires less data, and is more interpretable for regulatory settings.